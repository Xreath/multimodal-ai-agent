"""
Agent Nodes â€” LangGraph graph'Ä±nÄ±n node'larÄ± (iÅŸ yapan birimler).

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  LangGraph Node KavramÄ±                                         â•‘
â•‘                                                                  â•‘
â•‘  Node = Python fonksiyonu                                       â•‘
â•‘  - Girdi: AgentState (veya bir kÄ±smÄ±)                          â•‘
â•‘  - Ã‡Ä±ktÄ±: State gÃ¼ncellemesi (dict)                            â•‘
â•‘                                                                  â•‘
â•‘  Graph akÄ±ÅŸÄ±:                                                    â•‘
â•‘  START â†’ planner â†’ router â”€â”¬â”€â†’ vision â†’ reasoner â†’ evaluator   â•‘
â•‘                             â”œâ”€â†’ reasoner â†’ evaluator             â•‘
â•‘                             â””â”€â†’ respond â†’ END                    â•‘
â•‘                                                                  â•‘
â•‘  Evaluator kÃ¶tÃ¼ puan verirse â†’ planner'a geri dÃ¶ner (loop)      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Agent Patterns (MÃ¼lakat notu):

1. ReAct (Reason + Act):
   - DÃ¼ÅŸÃ¼n â†’ Hareket et â†’ GÃ¶zlemle â†’ Tekrarla
   - Basit, tek LLM Ã§aÄŸrÄ±sÄ±yla tool seÃ§imi
   - Bu projede: router + tool nodes

2. Plan-and-Execute:
   - Ã–nce plan yap (tÃ¼m adÄ±mlarÄ± belirle)
   - Sonra sÄ±rayla Ã§alÄ±ÅŸtÄ±r
   - Bu projede: planner node â†’ executor nodes

3. Reflection:
   - CevabÄ± Ã¼ret â†’ DeÄŸerlendir â†’ Gerekirse dÃ¼zelt
   - Bu projede: evaluator node â†’ loop back

Biz Ã¼Ã§Ã¼nÃ¼ birleÅŸtiriyoruz: Plan â†’ Execute (ReAct) â†’ Reflect
"""

import json
import sys
import os
from typing import Optional
from dotenv import load_dotenv

# Project path'leri
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
MONOREPO_ROOT = os.path.dirname(PROJECT_ROOT)

# .env dosyalarÄ±nÄ± yÃ¼kle â€” hem project3 hem project2'den
load_dotenv(os.path.join(PROJECT_ROOT, ".env"))
load_dotenv(os.path.join(MONOREPO_ROOT, "project2_llm_integration", ".env"))

# â”€â”€â”€ LLM Helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _get_openai_client():
    """
    DeepSeek LLM client oluÅŸtur â€” OpenAI SDK ile.

    DeepSeek'in API'si OpenAI-uyumlu olduÄŸu iÃ§in doÄŸrudan OpenAI SDK kullanÄ±yoruz.
    Bu, project2'ye baÄŸÄ±mlÄ±lÄ±ÄŸÄ± kaldÄ±rÄ±r ve daha temiz bir mimari saÄŸlar.

    MÃ¼lakat notu:
    - BirÃ§ok LLM provider (DeepSeek, Together, Groq) OpenAI-uyumlu API sunar
    - Bu sayede tek SDK (openai) ile birden fazla provider kullanÄ±labilir
    - Sadece base_url deÄŸiÅŸtirmek yeterli
    """
    from openai import OpenAI

    api_key = os.getenv("DEEPSEEK_API_KEY")
    if not api_key:
        raise ValueError(
            "DEEPSEEK_API_KEY environment variable not set.\n"
            "Create project3_agent_architecture/.env with:\n"
            "  DEEPSEEK_API_KEY=sk-your-key-here"
        )
    return OpenAI(api_key=api_key, base_url="https://api.deepseek.com")


# DeepSeek model adÄ±
_LLM_MODEL = "deepseek-chat"


def _call_llm(prompt: str, system_prompt: str = "", json_mode: bool = False) -> str:
    """
    Basit LLM Ã§aÄŸrÄ±sÄ± helper'Ä±.

    TÃ¼m node'lar bu fonksiyonu kullanarak LLM'e eriÅŸir.
    Merkezi LLM eriÅŸimi â†’ provider deÄŸiÅŸikliÄŸi tek noktadan.
    """
    client = _get_openai_client()
    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": prompt})

    kwargs = {
        "model": _LLM_MODEL,
        "messages": messages,
        "temperature": 0.3,
        "max_tokens": 2048,
    }
    if json_mode:
        kwargs["response_format"] = {"type": "json_object"}

    response = client.chat.completions.create(**kwargs)
    return response.choices[0].message.content


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NODE 1: PLANNER â€” GÃ¶revi adÄ±mlara bÃ¶ler
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PLANNER_SYSTEM_PROMPT = """Sen bir gÃ¶rev planlayÄ±cÄ±sÄ±n (task planner). KullanÄ±cÄ±nÄ±n isteÄŸini analiz edip
Ã§alÄ±ÅŸtÄ±rÄ±labilir adÄ±mlara bÃ¶l.

KullanÄ±labilir yetenekler:
- vision: GÃ¶rÃ¼ntÃ¼ analizi (nesne tespiti, segmentasyon, OCR)
- reason: Bilgiyi sentezleyip sonuÃ§ Ã§Ä±kar
- search: Bilgi ara (web search)
- calculate: Matematik hesaplama

Her adÄ±mÄ± kÄ±sa ve net yaz. JSON formatÄ±nda dÃ¶ndÃ¼r:
{
  "steps": ["adÄ±m1", "adÄ±m2", ...],
  "requires_vision": true/false,
  "complexity": "simple" | "moderate" | "complex"
}"""


def planner_node(state: dict) -> dict:
    """
    PLANNER NODE â€” KullanÄ±cÄ±nÄ±n isteÄŸini analiz edip plan oluÅŸturur.

    Bu node Plan-and-Execute pattern'Ä±nÄ±n "Plan" kÄ±smÄ±dÄ±r.
    LLM'i kullanarak karmaÅŸÄ±k bir gÃ¶revi adÄ±mlara bÃ¶ler.

    MÃ¼lakat notu:
    - Planning, agent'Ä±n en kritik yeteneÄŸi
    - KÃ¶tÃ¼ plan = kÃ¶tÃ¼ sonuÃ§ (garbage in, garbage out)
    - Plan complexity'ye gÃ¶re uyarlanmalÄ±: basit soru â†’ 1 adÄ±m, karmaÅŸÄ±k â†’ Ã§ok adÄ±m
    - Plan'Ä± state'e yazarak ÅŸeffaflÄ±k saÄŸlanÄ±r (explainability)

    Input (state'ten): user_query, image_path
    Output (state update): plan, next_action, messages
    """
    user_query = state["user_query"]
    image_path = state.get("image_path")

    print(f"\n{'='*60}")
    print(f"ğŸ§  PLANNER NODE")
    print(f"{'='*60}")
    print(f"Sorgu: {user_query}")
    print(f"GÃ¶rÃ¼ntÃ¼: {image_path or 'Yok'}")

    context = f"KullanÄ±cÄ± isteÄŸi: {user_query}"
    if image_path:
        context += f"\nGÃ¶rÃ¼ntÃ¼ mevcut: {image_path}"

    raw_response = _call_llm(context, PLANNER_SYSTEM_PROMPT, json_mode=True)

    # Parse plan
    try:
        parsed = json.loads(raw_response)
        steps = parsed.get("steps", [])
        requires_vision = parsed.get("requires_vision", bool(image_path))
        complexity = parsed.get("complexity", "moderate")
    except json.JSONDecodeError:
        steps = [f"DoÄŸrudan cevapla: {user_query}"]
        requires_vision = bool(image_path)
        complexity = "simple"

    print(f"Plan ({complexity}):")
    for i, step in enumerate(steps, 1):
        print(f"  {i}. {step}")

    # Ä°lk action'Ä± belirle
    if requires_vision and image_path:
        next_action = "vision"
    else:
        next_action = "reason"

    return {
        "plan": steps,
        "current_step": 0,
        "next_action": next_action,
        "iteration_count": state.get("iteration_count", 0) + 1,
        "messages": [{
            "role": "assistant",
            "content": f"[Planner] Plan oluÅŸturuldu ({len(steps)} adÄ±m, {complexity}): {', '.join(steps)}"
        }]
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NODE 2: ROUTER â€” Conditional edge (karar noktasÄ±)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def router_node(state: dict) -> str:
    """
    ROUTER â€” Conditional edge fonksiyonu.

    LangGraph'ta conditional_edges, state'e bakarak hangi node'a
    gidileceÄŸine karar verir. Bu bir "node" deÄŸil, bir "karar fonksiyonu".

    MÃ¼lakat notu:
    - LangGraph'ta iki tip edge var:
      1. Normal edge: A â†’ B (her zaman)
      2. Conditional edge: A â†’ router â†’ B veya C (state'e gÃ¶re)
    - Router fonksiyonu string dÃ¶ner â†’ edge mapping'de karÅŸÄ±lÄ±ÄŸÄ± olan node'a gider
    - Infinite loop korumasÄ±: max_iterations kontrolÃ¼ ÅŸart

    Input: state
    Output: string â†’ node adÄ± ("vision", "reason", "respond", "human_approval")
    """
    next_action = state.get("next_action", "reason")
    iteration_count = state.get("iteration_count", 0)
    max_iterations = state.get("max_iterations", 5)
    needs_approval = state.get("needs_human_approval", False)

    print(f"\n{'='*60}")
    print(f"ğŸ”€ ROUTER NODE")
    print(f"{'='*60}")

    # Sonsuz dÃ¶ngÃ¼ korumasÄ±
    if iteration_count >= max_iterations:
        print(f"âš ï¸  Max iterations ({max_iterations}) aÅŸÄ±ldÄ± â†’ respond")
        return "respond"

    # Human-in-the-loop kontrolÃ¼
    if needs_approval:
        print(f"ğŸ‘¤ Human approval gerekli â†’ human_approval")
        return "human_approval"

    print(f"Karar: {next_action} (iteration {iteration_count}/{max_iterations})")
    return next_action


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NODE 3: VISION â€” CV Pipeline Ã§alÄ±ÅŸtÄ±rÄ±r
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def vision_node(state: dict) -> dict:
    """
    VISION NODE â€” GÃ¶rÃ¼ntÃ¼yÃ¼ CV pipeline'dan geÃ§irir.

    Project 1'deki VisualPerceptionPipeline'Ä± Ã§aÄŸÄ±rÄ±r:
    - Object Detection (YOLOv8)
    - Instance Segmentation (YOLOv8-seg)
    - OCR (EasyOCR)

    MÃ¼lakat notu:
    - Bu node, agentic system'de "perception" katmanÄ±dÄ±r
    - Agent'Ä±n "gÃ¶zÃ¼" â€” dÃ¼nyayÄ± algÄ±lar
    - CV pipeline lazy-loaded: sadece gerektiÄŸinde yÃ¼klenir
    - SonuÃ§ state'e yazÄ±lÄ±r â†’ diÄŸer node'lar kullanabilir

    Input (state'ten): image_path
    Output (state update): cv_result, tool_results, next_action, messages
    """
    image_path = state.get("image_path")

    print(f"\n{'='*60}")
    print(f"ğŸ‘ï¸  VISION NODE")
    print(f"{'='*60}")

    if not image_path:
        print("âš ï¸  GÃ¶rÃ¼ntÃ¼ yolu yok â€” atlÄ±yorum")
        return {
            "cv_result": None,
            "next_action": "reason",
            "tool_results": [{"tool": "vision", "error": "No image path provided"}],
            "messages": [{"role": "assistant", "content": "[Vision] GÃ¶rÃ¼ntÃ¼ yolu belirtilmedi."}]
        }

    # CV Pipeline'Ä± yÃ¼kle ve Ã§alÄ±ÅŸtÄ±r
    # project1'in src/ dizinini import edebilmek iÃ§in sys.path yÃ¶netimi:
    # 1. project1'i path'e ekle (relative import'larÄ± Ã§Ã¶zmek iÃ§in)
    # 2. sys.modules'tan project3'Ã¼n 'src' modÃ¼lÃ¼nÃ¼ geÃ§ici kaldÄ±r
    # 3. Import yap
    # 4. Geri yÃ¼kle
    project1_path = os.path.join(MONOREPO_ROOT, "project1_cv_pipeline")

    # GeÃ§ici sys.path ve modules yÃ¶netimi
    old_src_module = sys.modules.pop("src", None)
    if project1_path not in sys.path:
        sys.path.insert(0, project1_path)

    from src.pipeline import VisualPerceptionPipeline
    pipeline = VisualPerceptionPipeline()

    # Geri yÃ¼kle
    if old_src_module is not None:
        sys.modules["src"] = old_src_module

    print(f"GÃ¶rÃ¼ntÃ¼ analiz ediliyor: {image_path}")
    cv_result = pipeline.analyze(image_path)

    # Ã–zet bilgi
    n_objects = len(cv_result.get("objects", []))
    n_segments = len(cv_result.get("segments", []))
    n_text = len(cv_result.get("text_regions", []))
    proc_time = cv_result.get("processing_time", {}).get("total", 0)

    summary = (
        f"Tespit: {n_objects} nesne, {n_segments} segment, {n_text} text bÃ¶lgesi "
        f"({proc_time:.2f}s)"
    )
    print(f"âœ… {summary}")

    return {
        "cv_result": cv_result,
        "next_action": "reason",
        "tool_results": [{
            "tool": "vision",
            "summary": summary,
            "objects": n_objects,
            "segments": n_segments,
            "text_regions": n_text,
            "processing_time": proc_time
        }],
        "messages": [{"role": "assistant", "content": f"[Vision] {summary}"}]
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NODE 4: REASONER â€” Bilgiyi sentezler, cevap Ã¼retir
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

REASONER_SYSTEM_PROMPT = """Sen bir multi-modal AI analisti sin. Sana verilen bilgileri
sentezleyerek kullanÄ±cÄ±nÄ±n sorusuna kapsamlÄ± ve doÄŸru cevap ver.

CevabÄ±nÄ± ÅŸu JSON formatÄ±nda ver:
{
  "answer": "Ana cevap (detaylÄ±, aÃ§Ä±klayÄ±cÄ±)",
  "reasoning_steps": ["adÄ±m1", "adÄ±m2", ...],
  "confidence": 0.0-1.0,
  "evidence": ["kanÄ±t1", "kanÄ±t2", ...],
  "follow_up_suggestions": ["Ã¶neri1", "Ã¶neri2"]
}

Kurallar:
- CV pipeline sonuÃ§larÄ±nÄ± kanÄ±t olarak kullan
- Emin olmadÄ±ÄŸÄ±n yerlerde confidence'Ä± dÃ¼ÅŸÃ¼r
- Somut sayÄ±lar ve veriler sun
- TÃ¼rkÃ§e cevap ver"""


def reasoner_node(state: dict) -> dict:
    """
    REASONER NODE â€” TÃ¼m bilgiyi sentezleyip cevap Ã¼retir.

    Bu node agentic system'de "reasoning" katmanÄ±dÄ±r.
    CV sonuÃ§larÄ±nÄ±, tool sonuÃ§larÄ±nÄ± ve konuÅŸma geÃ§miÅŸini
    birleÅŸtirip anlamlÄ± bir cevap Ã¼retir.

    MÃ¼lakat notu:
    - Reasoning = "sense-making" â€” ham veriyi anlama dÃ¶nÃ¼ÅŸtÃ¼rme
    - Context window yÃ¶netimi kritik: tÃ¼m bilgiyi sÄ±ÄŸdÄ±rmak lazÄ±m
    - Chain-of-Thought (CoT) prompting reasoning kalitesini artÄ±rÄ±r
    - Evidence-based reasoning: cevabÄ±n kanÄ±tlarÄ±nÄ± belirt

    Input (state'ten): user_query, cv_result, tool_results, plan
    Output (state update): reasoning, final_answer, next_action, messages
    """
    user_query = state["user_query"]
    cv_result = state.get("cv_result")
    tool_results = state.get("tool_results", [])
    plan = state.get("plan", [])

    print(f"\n{'='*60}")
    print(f"ğŸ¤” REASONER NODE")
    print(f"{'='*60}")

    # Context oluÅŸtur â€” LLM'e vereceÄŸimiz bilgi paketi
    context_parts = [f"KullanÄ±cÄ± sorusu: {user_query}"]

    if plan:
        context_parts.append(f"Plan: {', '.join(plan)}")

    if cv_result:
        # CV sonucunu Ã¶zetle (tÃ¼m JSON'Ä± gÃ¶ndermek yerine â€” token tasarrufu)
        cv_summary = _summarize_cv_result(cv_result)
        context_parts.append(f"CV Analiz Sonucu:\n{cv_summary}")

    if tool_results:
        context_parts.append(f"Tool SonuÃ§larÄ±:\n{json.dumps(tool_results, indent=2, ensure_ascii=False)}")

    full_context = "\n\n".join(context_parts)
    print(f"Context uzunluÄŸu: {len(full_context)} karakter")

    # LLM'e gÃ¶nder
    raw_response = _call_llm(full_context, REASONER_SYSTEM_PROMPT, json_mode=True)

    # Parse et
    try:
        parsed = json.loads(raw_response)
        answer = parsed.get("answer", raw_response)
        reasoning_steps = parsed.get("reasoning_steps", [])
        confidence = parsed.get("confidence", 0.5)
    except json.JSONDecodeError:
        answer = raw_response
        reasoning_steps = []
        confidence = 0.5

    print(f"Cevap uzunluÄŸu: {len(answer)} karakter")
    print(f"Confidence: {confidence}")
    print(f"Reasoning adÄ±mlarÄ±: {len(reasoning_steps)}")

    return {
        "reasoning": raw_response,
        "final_answer": answer,
        "next_action": "evaluate",
        "messages": [{
            "role": "assistant",
            "content": f"[Reasoner] Confidence: {confidence} | {answer[:200]}..."
        }]
    }


def _summarize_cv_result(cv_result: dict) -> str:
    """CV sonucunu Ã¶zet string'e dÃ¶nÃ¼ÅŸtÃ¼r (token tasarrufu iÃ§in)."""
    parts = []

    # Nesneler
    objects = cv_result.get("objects", [])
    if objects:
        # Nesne sayÄ±larÄ±nÄ± grupla
        from collections import Counter
        label_counts = Counter(o["label"] for o in objects)
        obj_summary = ", ".join(f"{count}x {label}" for label, count in label_counts.items())
        parts.append(f"Tespit edilen nesneler: {obj_summary}")

        # En yÃ¼ksek confidence
        max_conf = max(o["confidence"] for o in objects)
        parts.append(f"En yÃ¼ksek confidence: {max_conf:.2f}")

    # Text bÃ¶lgeleri
    text_regions = cv_result.get("text_regions", [])
    if text_regions:
        texts = [t["text"] for t in text_regions[:5]]  # Ä°lk 5
        parts.append(f"Tespit edilen metinler: {', '.join(texts)}")

    # Segmentler
    segments = cv_result.get("segments", [])
    if segments:
        parts.append(f"Segmentasyon: {len(segments)} segment")

    # GÃ¶rÃ¼ntÃ¼ bilgisi
    img_info = cv_result.get("image_info", {})
    if img_info:
        parts.append(f"GÃ¶rÃ¼ntÃ¼: {img_info.get('width', '?')}x{img_info.get('height', '?')}")

    return "\n".join(parts) if parts else "CV sonucu boÅŸ"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NODE 5: EVALUATOR â€” Cevap kalitesini deÄŸerlendirir
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EVALUATOR_SYSTEM_PROMPT = """Sen bir kalite deÄŸerlendirme uzmanÄ±sÄ±n. Verilen cevabÄ± deÄŸerlendir.

JSON formatÄ±nda dÃ¶ndÃ¼r:
{
  "score": 0.0-1.0,
  "feedback": "KÄ±sa deÄŸerlendirme",
  "pass": true/false,
  "improvement_suggestion": "Varsa iyileÅŸtirme Ã¶nerisi"
}

DeÄŸerlendirme kriterleri:
- DoÄŸruluk: Cevap soruyla uyumlu mu?
- KanÄ±t: CV verileri kullanÄ±lmÄ±ÅŸ mÄ±?
- BÃ¼tÃ¼nlÃ¼k: Soru tam cevaplanmÄ±ÅŸ mÄ±?
- Netlik: Cevap aÃ§Ä±k ve anlaÅŸÄ±lÄ±r mÄ±?

0.7 Ã¼stÃ¼ â†’ PASS, altÄ± â†’ FAIL (yeniden dene)"""


def evaluator_node(state: dict) -> dict:
    """
    EVALUATOR NODE â€” Reflection pattern: cevap kalitesini deÄŸerlendirir.

    Bu node "self-critique" mekanizmasÄ±dÄ±r. Agent'Ä±n kendi cevabÄ±nÄ±
    deÄŸerlendirip, yetersizse yeniden denemesini saÄŸlar.

    MÃ¼lakat notu:
    - Reflection/Self-critique: LLM'in kendi Ã§Ä±ktÄ±sÄ±nÄ± deÄŸerlendirmesi
    - Bu pattern cevap kalitesini Ã¶nemli Ã¶lÃ§Ã¼de artÄ±rÄ±r
    - Trade-off: Ekstra LLM Ã§aÄŸrÄ±sÄ± = daha yÃ¼ksek maliyet + latency
    - Infinite loop riski: max_iterations ile sÄ±nÄ±rla
    - Production'da: basit heuristic (uzunluk, format) + LLM evaluation hibrit

    Input (state'ten): user_query, final_answer, reasoning
    Output (state update): evaluation_score, evaluation_feedback, next_action
    """
    user_query = state["user_query"]
    final_answer = state.get("final_answer", "")
    iteration = state.get("iteration_count", 0)
    max_iter = state.get("max_iterations", 5)

    print(f"\n{'='*60}")
    print(f"ğŸ“Š EVALUATOR NODE")
    print(f"{'='*60}")

    eval_context = (
        f"Orijinal soru: {user_query}\n\n"
        f"Ãœretilen cevap: {final_answer}"
    )

    raw_response = _call_llm(eval_context, EVALUATOR_SYSTEM_PROMPT, json_mode=True)

    try:
        parsed = json.loads(raw_response)
        score = parsed.get("score", 0.5)
        feedback = parsed.get("feedback", "")
        passed = parsed.get("pass", score >= 0.7)
    except json.JSONDecodeError:
        score = 0.7
        feedback = "DeÄŸerlendirme parse edilemedi â€” varsayÄ±lan geÃ§iÅŸ"
        passed = True

    print(f"Skor: {score:.2f}")
    print(f"Feedback: {feedback}")
    print(f"GeÃ§ti mi: {'âœ… EVET' if passed else 'âŒ HAYIR'}")

    if passed or iteration >= max_iter - 1:
        next_action = "respond"
        if not passed:
            print(f"âš ï¸  Skor dÃ¼ÅŸÃ¼k ama max iteration'a ulaÅŸÄ±ldÄ± â†’ respond")
    else:
        next_action = "reason"
        print(f"ğŸ”„ Yeniden deneniyor (iteration {iteration}/{max_iter})")

    return {
        "evaluation_score": score,
        "evaluation_feedback": feedback,
        "next_action": next_action,
        "messages": [{
            "role": "assistant",
            "content": f"[Evaluator] Skor: {score:.2f} â€” {feedback}"
        }]
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NODE 6: RESPOND â€” Final cevabÄ± oluÅŸturur
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def respond_node(state: dict) -> dict:
    """
    RESPOND NODE â€” KullanÄ±cÄ±ya verilecek final cevabÄ± hazÄ±rlar.

    Basit bir formatlama node'u. State'teki final_answer'Ä±
    kullanÄ±cÄ±ya uygun formata getirir.

    Input (state'ten): final_answer, evaluation_score, plan, tool_results
    Output (state update): final_answer (formatted), messages
    """
    final_answer = state.get("final_answer", "Cevap Ã¼retilemedi.")
    score = state.get("evaluation_score")
    plan = state.get("plan", [])
    tool_results = state.get("tool_results", [])

    print(f"\n{'='*60}")
    print(f"ğŸ’¬ RESPOND NODE")
    print(f"{'='*60}")

    # ZenginleÅŸtirilmiÅŸ cevap formatÄ±
    response_parts = [final_answer]

    if tool_results:
        tools_used = set(tr.get("tool", "unknown") for tr in tool_results)
        response_parts.append(f"\nğŸ“ KullanÄ±lan araÃ§lar: {', '.join(tools_used)}")

    if score is not None:
        response_parts.append(f"ğŸ“Š GÃ¼ven skoru: {score:.0%}")

    formatted_answer = "\n".join(response_parts)
    print(f"Final cevap ({len(formatted_answer)} karakter)")

    return {
        "final_answer": formatted_answer,
        "messages": [{
            "role": "assistant",
            "content": formatted_answer
        }]
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# NODE 7: HUMAN APPROVAL â€” Ä°nsan onayÄ± bekler
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def human_approval_node(state: dict) -> dict:
    """
    HUMAN-IN-THE-LOOP NODE â€” Kritik kararlarda insan onayÄ± bekler.

    LangGraph'ta human-in-the-loop iki ÅŸekilde yapÄ±labilir:
    1. interrupt_before/interrupt_after â€” graph'Ä± durdur, insan karar versin
    2. Approval node â€” state'e bakarak onay iste

    Biz burada 2. yÃ¶ntemi kullanÄ±yoruz (daha basit, daha esnek).

    MÃ¼lakat notu:
    - Human-in-the-loop neden gerekli?
      â†’ GÃ¼venlik: yanlÄ±ÅŸ kararlarÄ±n maliyeti yÃ¼ksekse (silme, gÃ¶nderme)
      â†’ Etik: hassas verilerle Ã§alÄ±ÅŸÄ±rken
      â†’ DÃ¼zenleyici: compliance gereksinimleri
    - Ne zaman kullanÄ±lMAZ?
      â†’ Latency kritikse (real-time sistemler)
      â†’ Karar dÃ¼ÅŸÃ¼k riskli ise
    - LangGraph interrupt: graph checkpointed â†’ durdurup devam ettirilebilir
    """
    print(f"\n{'='*60}")
    print(f"ğŸ‘¤ HUMAN APPROVAL NODE")
    print(f"{'='*60}")

    plan = state.get("plan", [])
    print(f"Plan: {plan}")
    print(f"Onay bekleniyor...")

    # CLI'da input ile onay al
    try:
        approval = input("\nâœ‹ Bu planÄ± onaylÄ±yor musunuz? (e/h): ").strip().lower()
    except EOFError:
        approval = "e"  # Non-interactive modda otomatik onayla

    if approval in ("e", "evet", "y", "yes"):
        print("âœ… OnaylandÄ± â€” devam ediliyor")
        return {
            "needs_human_approval": False,
            "next_action": "vision" if state.get("image_path") else "reason",
            "messages": [{"role": "user", "content": "[Human] Plan onaylandÄ±."}]
        }
    else:
        print("âŒ Reddedildi â€” yeniden planlama")
        return {
            "needs_human_approval": False,
            "next_action": "respond",
            "final_answer": "Ä°ÅŸlem kullanÄ±cÄ± tarafÄ±ndan iptal edildi.",
            "messages": [{"role": "user", "content": "[Human] Plan reddedildi."}]
        }
