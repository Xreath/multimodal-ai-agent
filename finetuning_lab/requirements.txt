# Project 4: Fine-tuning Lab
# Core ML
torch>=2.0.0
torchvision>=0.15.0

# CV Fine-tuning
ultralytics>=8.0.0
albumentations>=1.3.0

# LLM Fine-tuning
transformers>=4.40.0
peft>=0.12.0
datasets>=2.20.0
accelerate>=0.30.0
trl>=0.9.0

# bitsandbytes: CUDA-only for quantization
# On Mac/MPS, we use fp16 instead
# bitsandbytes>=0.43.0

# Evaluation & Monitoring
scikit-learn>=1.3.0
matplotlib>=3.7.0
seaborn>=0.12.0
tensorboard>=2.14.0

# Utilities
pyyaml>=6.0
python-dotenv>=1.0.0
tqdm>=4.65.0
huggingface-hub>=0.23.0
